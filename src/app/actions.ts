"use server";
import { generateStartingPrompts } from '@/ai/flows/generate-starting-prompts';
import { summarizeModelResponse } from '@/ai/flows/summarize-model-response';
import { MODELS } from '@/lib/constants';
import type { IndividualResponse } from '@/lib/types';
import { ai } from '@/ai/genkit';

async function getDummyResponse(prompt: string, modelName: string) {
  await new Promise(resolve => setTimeout(resolve, 1500 + Math.random() * 1000)); 
  return `This is a simulated response from **${modelName}** for the prompt: *"${prompt}"*.

ModelVerse is designed to be a clean and intuitive interface. Here are some of its features:

- **Model Selection**: Easily switch between models.
- **Unified Response**: Consistent output format.
- **Configuration**: Adjust parameters like temperature.

Here is a sample code block in JavaScript:
\`\`\`javascript
function greet(name) {
  // This function greets the user with the provided name.
  console.log(\`Hello, \${name}! Welcome to ModelVerse.\`);
}

greet('${modelName}');
\`\`\`

And a Python example:
\`\`\`python
def main():
    # Main function to demonstrate Python code
    model = "${modelName}"
    print(f"This response was generated by {model}.")

if __name__ == "__main__":
    main()
\`\`\`

The goal is to provide a seamless and powerful user experience.`;
}

export async function getSuggestions(modelName: string) {
  try {
    const result = await generateStartingPrompts({ modelName });
    return result.prompts;
  } catch (error) {
    console.error("Error fetching suggestions:", error);
    // Return fallback prompts on error
    return [
        `What is the history of ${modelName}?`,
        `Write a short story in the style of a noir detective, where the main character is ${modelName}.`,
        `Explain the concept of neural networks like I'm five.`,
        `Generate a python script to parse a CSV file.`,
        `What are some creative uses for ${modelName}?`
    ];
  }
}

export async function processPrompt(prompt: string, modelName: string, apiKeys: Record<string, string>) {
  const modelInfo = MODELS.find(m => m.name === modelName);
  let response = '';

  try {
    if (modelInfo && apiKeys[modelInfo.id]) {
        const model = ai.model(modelInfo.id as any);
        const result = await ai.generate({ model, prompt, config: { apiKey: apiKeys[modelInfo.id] }});
        response = result.text;
    } else {
      response = await getDummyResponse(prompt, modelName);
    }
  } catch (error) {
    console.error(`Error with ${modelName}:`, error);
    response = `Error fetching response from ${modelName}. Falling back to dummy response.\n\n` + await getDummyResponse(prompt, modelName);
  }
  
  try {
    const summaryResult = await summarizeModelResponse({ modelResponse: response });
    return {
      response,
      summary: summaryResult.summary,
    };
  } catch(error) {
    console.error("Error summarizing response:", error);
    return {
        response,
        summary: "Could not generate summary for this response.",
    }
  }
}

export async function processPromptAll(prompt: string, apiKeys: Record<string, string>): Promise<Omit<IndividualResponse, 'model'> & { model: { id: string; name: string; } }[]> {
  const allModelResponses = await Promise.all(
    MODELS.map(async (model) => {
      try {
        const result = await processPrompt(prompt, model.name, apiKeys);
        // Return a serializable object, excluding the Icon component
        return {
          model: { id: model.id, name: model.name },
          ...result,
        };
      } catch (error) {
        console.error(`Error processing prompt for ${model.name}:`, error);
        const dummyResponse = await getDummyResponse(prompt, model.name);
        return {
          model: { id: model.id, name: model.name },
          response: `Error fetching response from ${model.name}.\n\n${dummyResponse}`,
          summary: "Error generating summary."
        };
      }
    })
  );

  return allModelResponses;
}
